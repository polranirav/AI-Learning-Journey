{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cace39d9-618d-4cbc-9098-125581b13c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a37729c-7b44-43a0-8bf9-2ac932e36dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6080f2e4-25d2-4d7f-9ecc-8dd8d20b1e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7987b50b-77ff-4572-90b7-3c9db90f9548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab9409e-59e5-4e13-b189-7dd3746d0640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea6c3f8-1a9e-42a2-98d8-ccb28aa3644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c306c97-bac9-4fdb-9b01-86b4c087ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90636a7-d8c3-496e-a588-78d8795d71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce706313-9341-40ba-8753-a84d523c26bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e659c30e-0856-4962-a7ad-eeba939ed678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ccdc596-0d38-4187-9008-270f24fd6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split (X,y,test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b319bff-3b78-470c-8c9f-bda1a46230a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>320</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>315</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>336</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>306</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>302</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "18         318          110                  3  4.0   3.0  8.80         0\n",
       "202        340          120                  5  4.5   4.5  9.91         1\n",
       "250        320          104                  3  3.0   2.5  8.57         1\n",
       "274        315          100                  1  2.0   2.5  7.95         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "71         336          112                  5  5.0   5.0  9.76         1\n",
       "106        329          111                  4  4.5   4.5  9.18         1\n",
       "270        306          105                  2  2.5   3.0  8.22         1\n",
       "348        302           99                  1  2.0   2.0  7.25         0\n",
       "102        314          106                  2  4.0   3.5  8.25         0\n",
       "\n",
       "[320 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33245aeb-1c58-40be-9048-cafede726e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f67e735-073c-4853-8048-0aac42a911e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0120c5f0-c29a-4c0d-8974-f46493cae675",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaler = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b44a6f7d-53d7-43c9-acb4-6173b85cfe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64      , 0.64285714, 0.5       , ..., 0.375     , 0.59935897,\n",
       "        1.        ],\n",
       "       [0.56      , 0.64285714, 0.5       , ..., 0.5       , 0.64102564,\n",
       "        0.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 0.875     , 0.99679487,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.32      , 0.46428571, 0.25      , ..., 0.5       , 0.45512821,\n",
       "        1.        ],\n",
       "       [0.24      , 0.25      , 0.        , ..., 0.25      , 0.14423077,\n",
       "        0.        ],\n",
       "       [0.48      , 0.5       , 0.25      , ..., 0.625     , 0.46474359,\n",
       "        0.        ]], shape=(320, 7))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a86b5d3f-d615-439c-95e3-e0a77f4dcf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11363636, 0.36      , 0.5       , 0.57142857, 0.71428571,\n",
       "        0.29752066, 1.        ],\n",
       "       [0.34090909, 0.28      , 0.5       , 0.85714286, 0.71428571,\n",
       "        0.51239669, 1.        ],\n",
       "       [1.        , 0.76      , 1.        , 0.71428571, 0.71428571,\n",
       "        0.90909091, 1.        ],\n",
       "       [0.65909091, 0.52      , 0.75      , 0.85714286, 0.71428571,\n",
       "        0.68595041, 1.        ],\n",
       "       [0.11363636, 0.08      , 0.25      , 0.42857143, 0.42857143,\n",
       "        0.19834711, 1.        ],\n",
       "       [1.        , 0.8       , 1.        , 0.85714286, 0.85714286,\n",
       "        0.84710744, 1.        ],\n",
       "       [0.02272727, 0.04      , 0.25      , 0.28571429, 0.        ,\n",
       "        0.20247934, 0.        ],\n",
       "       [0.15909091, 0.16      , 0.5       , 0.14285714, 0.28571429,\n",
       "        0.10743802, 0.        ],\n",
       "       [0.36363636, 0.4       , 0.25      , 0.14285714, 0.28571429,\n",
       "        0.4338843 , 0.        ],\n",
       "       [0.61363636, 0.72      , 0.5       , 0.71428571, 0.42857143,\n",
       "        0.79338843, 1.        ],\n",
       "       [0.61363636, 0.52      , 0.5       , 0.57142857, 0.42857143,\n",
       "        0.49586777, 0.        ],\n",
       "       [0.86363636, 0.84      , 0.75      , 0.71428571, 0.57142857,\n",
       "        0.88429752, 1.        ],\n",
       "       [0.45454545, 0.28      , 0.5       , 0.14285714, 0.42857143,\n",
       "        0.        , 0.        ],\n",
       "       [0.56818182, 0.64      , 1.        , 1.        , 1.        ,\n",
       "        0.84710744, 1.        ],\n",
       "       [0.29545455, 0.4       , 1.        , 0.57142857, 0.57142857,\n",
       "        0.47933884, 0.        ],\n",
       "       [0.38636364, 0.48      , 0.25      , 0.28571429, 0.14285714,\n",
       "        0.45454545, 1.        ],\n",
       "       [0.27272727, 0.32      , 0.25      , 0.42857143, 0.57142857,\n",
       "        0.45041322, 0.        ],\n",
       "       [0.02272727, 0.04      , 0.25      , 0.28571429, 0.14285714,\n",
       "        0.01239669, 0.        ],\n",
       "       [0.52272727, 0.44      , 0.5       , 0.57142857, 0.28571429,\n",
       "        0.38429752, 1.        ],\n",
       "       [0.88636364, 0.88      , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ],\n",
       "       [0.11363636, 0.16      , 0.25      , 0.42857143, 0.14285714,\n",
       "        0.33884298, 0.        ],\n",
       "       [0.40909091, 0.4       , 0.5       , 0.57142857, 0.28571429,\n",
       "        0.37190083, 0.        ],\n",
       "       [0.5       , 0.44      , 0.5       , 0.14285714, 0.42857143,\n",
       "        0.51652893, 0.        ],\n",
       "       [0.06818182, 0.04      , 0.25      , 0.        , 0.14285714,\n",
       "        0.19008264, 0.        ],\n",
       "       [0.93181818, 0.92      , 0.75      , 0.85714286, 0.85714286,\n",
       "        0.92975207, 1.        ],\n",
       "       [0.65909091, 0.48      , 0.5       , 0.42857143, 0.57142857,\n",
       "        0.70661157, 1.        ],\n",
       "       [0.34090909, 0.4       , 0.5       , 0.57142857, 0.42857143,\n",
       "        0.4338843 , 1.        ],\n",
       "       [0.        , 0.16      , 0.25      , 0.28571429, 0.28571429,\n",
       "        0.26033058, 0.        ],\n",
       "       [0.27272727, 0.32      , 0.25      , 0.28571429, 0.71428571,\n",
       "        0.39669421, 1.        ],\n",
       "       [0.68181818, 0.68      , 0.5       , 0.57142857, 0.42857143,\n",
       "        0.68181818, 1.        ],\n",
       "       [0.63636364, 0.6       , 0.5       , 0.57142857, 0.57142857,\n",
       "        0.67768595, 1.        ],\n",
       "       [0.90909091, 0.92      , 1.        , 0.85714286, 1.        ,\n",
       "        0.88016529, 1.        ],\n",
       "       [0.36363636, 0.36      , 0.5       , 0.57142857, 0.71428571,\n",
       "        0.28512397, 0.        ],\n",
       "       [0.04545455, 0.16      , 0.25      , 0.71428571, 0.14285714,\n",
       "        0.08264463, 0.        ],\n",
       "       [0.36363636, 0.48      , 0.25      , 0.28571429, 0.57142857,\n",
       "        0.35950413, 0.        ],\n",
       "       [0.06818182, 0.28      , 0.5       , 0.71428571, 0.57142857,\n",
       "        0.50413223, 0.        ],\n",
       "       [0.54545455, 0.6       , 0.25      , 0.71428571, 0.57142857,\n",
       "        0.47933884, 0.        ],\n",
       "       [0.27272727, 0.44      , 0.5       , 0.42857143, 0.42857143,\n",
       "        0.34710744, 0.        ],\n",
       "       [0.22727273, 0.44      , 0.25      , 0.14285714, 0.28571429,\n",
       "        0.30578512, 0.        ],\n",
       "       [0.81818182, 0.92      , 0.25      , 0.85714286, 0.57142857,\n",
       "        0.80991736, 1.        ],\n",
       "       [0.52272727, 0.4       , 0.5       , 0.42857143, 0.57142857,\n",
       "        0.52479339, 1.        ],\n",
       "       [0.54545455, 0.32      , 0.5       , 0.42857143, 0.42857143,\n",
       "        0.12396694, 0.        ],\n",
       "       [0.70454545, 0.68      , 0.5       , 0.42857143, 0.42857143,\n",
       "        0.54545455, 1.        ],\n",
       "       [1.        , 1.        , 1.        , 0.85714286, 0.85714286,\n",
       "        0.90909091, 1.        ],\n",
       "       [0.54545455, 0.6       , 1.        , 1.        , 0.85714286,\n",
       "        0.75206612, 1.        ],\n",
       "       [0.63636364, 0.6       , 0.75      , 0.85714286, 0.71428571,\n",
       "        0.7231405 , 1.        ],\n",
       "       [0.97727273, 0.84      , 0.75      , 0.71428571, 0.57142857,\n",
       "        0.99173554, 1.        ],\n",
       "       [0.20454545, 0.48      , 0.25      , 0.28571429, 0.28571429,\n",
       "        0.4214876 , 0.        ],\n",
       "       [0.72727273, 0.84      , 1.        , 1.        , 1.        ,\n",
       "        0.8677686 , 1.        ],\n",
       "       [0.61363636, 0.72      , 0.75      , 0.71428571, 0.85714286,\n",
       "        0.75619835, 1.        ],\n",
       "       [0.75      , 0.76      , 1.        , 0.71428571, 1.        ,\n",
       "        0.78512397, 1.        ],\n",
       "       [0.61363636, 0.36      , 0.5       , 0.71428571, 0.71428571,\n",
       "        0.42975207, 1.        ],\n",
       "       [0.61363636, 0.52      , 1.        , 0.71428571, 0.71428571,\n",
       "        0.55371901, 1.        ],\n",
       "       [0.81818182, 0.92      , 1.        , 1.        , 1.        ,\n",
       "        0.92561983, 1.        ],\n",
       "       [0.43181818, 0.4       , 0.25      , 0.14285714, 0.28571429,\n",
       "        0.10330579, 0.        ],\n",
       "       [0.25      , 0.52      , 0.25      , 0.71428571, 0.57142857,\n",
       "        0.12396694, 0.        ],\n",
       "       [0.27272727, 0.56      , 0.25      , 0.42857143, 0.71428571,\n",
       "        0.4338843 , 0.        ],\n",
       "       [0.59090909, 0.6       , 0.75      , 0.71428571, 1.        ,\n",
       "        0.71487603, 1.        ],\n",
       "       [0.09090909, 0.08      , 0.25      , 0.42857143, 0.42857143,\n",
       "        0.2892562 , 1.        ],\n",
       "       [0.56818182, 0.68      , 1.        , 1.        , 1.        ,\n",
       "        0.68595041, 1.        ],\n",
       "       [0.11363636, 0.44      , 0.75      , 0.28571429, 0.42857143,\n",
       "        0.44214876, 0.        ],\n",
       "       [0.45454545, 0.24      , 0.25      , 0.28571429, 0.14285714,\n",
       "        0.38016529, 1.        ],\n",
       "       [0.25      , 0.6       , 0.75      , 0.71428571, 0.85714286,\n",
       "        0.40082645, 0.        ],\n",
       "       [0.        , 0.        , 0.25      , 0.42857143, 0.14285714,\n",
       "        0.05785124, 1.        ],\n",
       "       [0.36363636, 0.4       , 0.25      , 0.28571429, 0.42857143,\n",
       "        0.29752066, 0.        ],\n",
       "       [0.70454545, 0.32      , 0.5       , 0.71428571, 0.71428571,\n",
       "        0.37190083, 1.        ],\n",
       "       [0.15909091, 0.2       , 0.25      , 0.42857143, 0.57142857,\n",
       "        0.27272727, 1.        ],\n",
       "       [0.70454545, 0.72      , 0.75      , 0.85714286, 1.        ,\n",
       "        0.71900826, 0.        ],\n",
       "       [0.75      , 0.64      , 0.75      , 0.85714286, 0.71428571,\n",
       "        0.75619835, 1.        ],\n",
       "       [0.40909091, 0.52      , 0.75      , 0.85714286, 0.71428571,\n",
       "        0.67768595, 1.        ],\n",
       "       [0.47727273, 0.44      , 0.5       , 0.71428571, 0.57142857,\n",
       "        0.45454545, 1.        ],\n",
       "       [0.75      , 0.6       , 0.25      , 0.71428571, 0.42857143,\n",
       "        0.7231405 , 1.        ],\n",
       "       [0.77272727, 0.8       , 1.        , 0.85714286, 0.42857143,\n",
       "        0.80165289, 1.        ],\n",
       "       [0.59090909, 0.6       , 1.        , 1.        , 0.71428571,\n",
       "        0.70247934, 1.        ],\n",
       "       [0.        , 0.08      , 0.25      , 0.        , 0.14285714,\n",
       "        0.16528926, 0.        ],\n",
       "       [0.45454545, 0.4       , 0.5       , 0.42857143, 0.57142857,\n",
       "        0.54958678, 0.        ],\n",
       "       [0.36363636, 0.6       , 0.25      , 0.57142857, 0.42857143,\n",
       "        0.46694215, 0.        ],\n",
       "       [0.11363636, 0.12      , 0.        , 0.14285714, 0.42857143,\n",
       "        0.26033058, 1.        ],\n",
       "       [0.75      , 0.96      , 0.75      , 0.85714286, 0.85714286,\n",
       "        0.72727273, 1.        ],\n",
       "       [0.38636364, 0.56      , 0.5       , 0.71428571, 0.57142857,\n",
       "        0.66115702, 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec10968d-18ba-4577-a5ee-79ccc2d41b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a613c2-0567-46f2-97c1-a5a002a899e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a13e469-a7ea-4f8d-97d7-9b96bff1b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niravpolara/PycharmProjects/AI-Learning-Journey/venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05fb198c-3042-4db8-9418-6d03d5b7444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c5edd03-4545-47c7-88aa-0224f33fa51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0709 - val_loss: 0.0503\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0453 - val_loss: 0.0296\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0269 - val_loss: 0.0162\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0040\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "history = model.fit(X_train_scaled,y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fdc1345-c6da-422b-96c4-0f2c6a24f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "703eabde-b550-40d4-8ac7-06e67ecd3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eacaf352-70ca-47d9-8ec7-775374a15789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884527492416751"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bd28907-15d4-44a1-9eab-afef20cb0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fe4df60-4d7d-4ace-8c59-21f6a2bd215d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159d16ad0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82353f8d-8db8-478e-90c7-d820d7c21832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
