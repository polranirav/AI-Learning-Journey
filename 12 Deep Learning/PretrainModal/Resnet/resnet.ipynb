{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6a7b9f-9d65-43a1-8120-c70bc09d265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed795259-e341-40a7-93db-2bf8cc1c59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8784f28f-c12c-47bf-8c3c-846f60d88c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'boy.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97854be-7323-46ac-89e3-7a7177e5feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32efd16c-2ecf-4c90-9f3f-aeb132fdbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Predicted [('n02317335', 'starfish', np.float32(0.104439095)), ('n01978287', 'Dungeness_crab', np.float32(0.097527325)), ('n10565667', 'scuba_diver', np.float32(0.050597113))]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93624287-b598-4bf0-a969-08bde2ad09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = 'rose.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b13e7cd-8001-4b07-b112-3322f8692b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img2, target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cecdf5cb-71ed-4d7b-ad55-8297d69609d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Predicted [('n03443371', 'goblet', np.float32(0.15530339)), ('n03916031', 'perfume', np.float32(0.11397401)), ('n01833805', 'hummingbird', np.float32(0.10643159))]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d6ce3c-fa93-4841-be53-7e3c8604d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = 'girl.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db55fd72-033e-41ca-ab20-0da83379a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img2, target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001a976d-ca3b-455e-a052-ebf992b5556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted [('n03404251', 'fur_coat', np.float32(0.19505689)), ('n04584207', 'wig', np.float32(0.11319913)), ('n03476991', 'hair_spray', np.float32(0.07738092))]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0af27932-9350-4dae-b72d-5e88d7ff10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = 'man.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f13009c1-8ec7-4a43-91cd-15ae2eb6e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img4, target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce16a139-5189-49cb-a1de-888206197a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "Predicted [('n02730930', 'apron', np.float32(0.24974248)), ('n02317335', 'starfish', np.float32(0.13094403)), ('n04136333', 'sarong', np.float32(0.115712196))]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67d58ff-f3bf-4601-a862-7b74ed46fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img5 = 'kk.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c239fa8-0e34-4a8f-820b-420270104ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img5, target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "077a5371-477d-4574-8be5-f5946c43b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted [('n03000247', 'chain_mail', np.float32(0.40550908)), ('n03721384', 'marimba', np.float32(0.15880191)), ('n03141823', 'crutch', np.float32(0.06483889))]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8e4ee-817b-42cc-bad2-170c87bda4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
