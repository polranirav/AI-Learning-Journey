{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polranirav/AI-Learning-Journey/blob/main/12%20Deep%20Learning/LSTM/Project/lstm_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About the Program\n",
        "This program follows a monthly subscription model at Rs 799 per month.\n",
        "The total duration of the DSMP is seven months.\n",
        "The approximate overall fee across seven months is Rs 5600.\n",
        "You can join anytime without waiting for a new batch to start.\n",
        "All live sessions are recorded for later viewing.\n",
        "Session recordings appear in your dashboard after class.\n",
        "Typical live sessions run for about two hours.\n",
        "The teaching language used in class is Hinglish.\n",
        "Non-technical learners are welcome to enroll and start from basics.\n",
        "Joining mid-way still grants access to past recordings during validity.\n",
        "\n",
        "Syllabus Overview\n",
        "The syllabus covers Python Fundamentals for complete beginners.\n",
        "You will learn Python libraries used in Data Science work.\n",
        "Data Analysis modules focus on EDA and storytelling with data.\n",
        "SQL for Data Science includes joins and window functions.\n",
        "Maths for Machine Learning keeps intuition first and formulas second.\n",
        "ML Algorithms include supervised and unsupervised techniques.\n",
        "Practical ML focuses on pipelines, validation, and feature engineering.\n",
        "MLOps introduces experiment tracking, packaging, and simple CI/CD.\n",
        "Case studies simulate realistic business problems and decisions.\n",
        "Deep Learning and NLP are not part of this curriculum.\n",
        "\n",
        "Links and Resources\n",
        "You can check detailed syllabus on the official course page.\n",
        "The monthly timetable is shared through a public Google Sheet.\n",
        "Official payments are made only through the course website.\n",
        "Reminder emails are sent before each paid session.\n",
        "Dashboard access shows recordings, notes, and the doubt form.\n",
        "\n",
        "Live Sessions\n",
        "If you miss a session, you can watch the recording later.\n",
        "Most sessions last roughly one hundred and twenty minutes.\n",
        "Slides are primarily in English with Hinglish explanations.\n",
        "Q&A time is reserved at the end of the session.\n",
        "Weekly schedules are announced on the shared sheet.\n",
        "\n",
        "Access and Validity\n",
        "Your subscription is valid for thirty days from purchase time.\n",
        "Renewals extend your access window by another thirty days.\n",
        "During an active cycle, past paid content remains unlocked.\n",
        "If your validity lapses, you will need to renew to continue.\n",
        "Joining on any date shifts your next renewal to that date.\n",
        "\n",
        "Refund Policy\n",
        "A seven-day refund window starts from your payment date.\n",
        "Refunds requested after seven days are not eligible.\n",
        "Plan your first week to evaluate fit before the window closes.\n",
        "Contact support if you need help initiating a refund request.\n",
        "Refunds apply to the latest payment within policy limits.\n",
        "\n",
        "Payments\n",
        "Monthly payments must be made on the official website.\n",
        "Do not pay through third-party links or private messages.\n",
        "Receipts are emailed after successful payment processing.\n",
        "International payment issues can be escalated by email.\n",
        "Include your registered email and phone number when writing support.\n",
        "\n",
        "Eligibility and Onboarding\n",
        "Beginners from non-tech backgrounds can join confidently.\n",
        "The course starts from Python basics and builds gradually.\n",
        "You can jump in mid-month and begin with recordings.\n",
        "Your dashboard unlocks immediately after successful payment.\n",
        "Orientation notes help you navigate the platform quickly.\n",
        "\n",
        "Doubt Support\n",
        "You can fill a doubt form through the dashboard.\n",
        "The team schedules one-on-one clarity calls for complex issues.\n",
        "Past-week doubts can still be raised using the form option.\n",
        "Provide examples or screenshots to speed up resolution.\n",
        "Response times are communicated after form submission.\n",
        "\n",
        "Certificate Criteria\n",
        "You must complete full fee payment across seven months.\n",
        "You must attempt all course assessments to qualify.\n",
        "Certificates are issued to learners who meet both criteria.\n",
        "Assessments emphasize applied understanding over rote math.\n",
        "Keep submission notes concise and clearly structured.\n",
        "\n",
        "Placement Assistance\n",
        "Placement assistance does not imply a placement guarantee.\n",
        "Job offers or interviews are not guaranteed by the program.\n",
        "Assistance includes portfolio building and resume guidance.\n",
        "Soft-skill sessions improve communication and interviews.\n",
        "Mentor sessions add real-world perspective and feedback.\n",
        "Job hunting strategies cover ATS keywords and outreach.\n",
        "You should expect guidance, not assured outcomes.\n",
        "\n",
        "Content Emphasis\n",
        "Python Fundamentals cover syntax, control flow, and functions.\n",
        "Libraries for DS include NumPy, Pandas, and Matplotlib.\n",
        "Data Analysis focuses on tidy data and reproducible EDA.\n",
        "SQL practice builds confidence with joins and aggregates.\n",
        "Maths for ML develops intuition for vectors and gradients.\n",
        "Algorithms include linear models, trees, and clustering.\n",
        "Practical ML stresses pipelines and validation rigor.\n",
        "MLOps introduces tracking, packaging, and deployments.\n",
        "Case studies connect methods to business decisions.\n",
        "\n",
        "Recordings and Dashboard\n",
        "Recordings are your safety net for missed classes.\n",
        "Videos appear in the dashboard within the validity period.\n",
        "Downloadable resources are attached where permitted.\n",
        "You can rewatch tricky segments at your own pace.\n",
        "Keep personal notes aligned to each module outcome.\n",
        "\n",
        "Scheduling\n",
        "Typical classes run in the evening IST schedule.\n",
        "Exact start times are posted on the weekly sheet.\n",
        "Reminder emails arrive before each live session.\n",
        "Calendar links may be provided for convenience.\n",
        "Check the sheet regularly for any timing updates.\n",
        "\n",
        "Policies and Safety\n",
        "Always pay only through the official website link.\n",
        "Never share OTPs or passwords with anyone.\n",
        "Support will never ask for your confidential info.\n",
        "Use the listed emails for payment-related queries.\n",
        "Verify URLs before completing a transaction.\n",
        "\n",
        "International Learners\n",
        "If cards fail, contact support for alternatives.\n",
        "Share transaction error screenshots for faster help.\n",
        "Confirm time zone differences for live sessions.\n",
        "Recordings help when time zones are challenging.\n",
        "Support provides guidance tailored to your region.\n",
        "\n",
        "Learning Approach\n",
        "Focus on clarity and reproducibility over complexity.\n",
        "Start with baseline models before heavy tuning.\n",
        "Use proper validation to avoid leakage pitfalls.\n",
        "Document assumptions at the top of each notebook.\n",
        "Prefer readable code and clear variable names.\n",
        "\n",
        "Evaluation Style\n",
        "Assessments are short and focused on application.\n",
        "Rubrics reward reasoning and decision justification.\n",
        "Error analysis is valued alongside metric scores.\n",
        "Write concise summaries of your modeling choices.\n",
        "Link metrics to practical business costs where possible.\n",
        "\n",
        "Practical Tips\n",
        "Pin library versions to stabilize your environment.\n",
        "Seed randomness to reproduce key results consistently.\n",
        "Keep datasets versioned as experiments progress.\n",
        "Use checklists to reduce last-minute mistakes.\n",
        "Save artifacts with consistent naming conventions.\n",
        "\n",
        "SQL Module Highlights\n",
        "Practice joins across fact and dimension tables.\n",
        "Use window functions for rankings and rolling stats.\n",
        "Write groupby summaries at meaningful aggregation levels.\n",
        "Consider indexes and query plans for performance.\n",
        "Write clear SQL with consistent formatting.\n",
        "\n",
        "Pandas and Visualization\n",
        "Indexing and selection patterns improve readability.\n",
        "Groupby pipelines summarize behavior effectively.\n",
        "Avoid chained operations when clarity suffers.\n",
        "Label axes and titles for meaningful charts.\n",
        "Choose appropriate scales for honest visuals.\n",
        "\n",
        "Maths Essentials\n",
        "Vectors and matrices are introduced with intuition.\n",
        "Gradients are linked to simple geometric ideas.\n",
        "Bias-variance tradeoff is explained with examples.\n",
        "Probability basics support reasoning under uncertainty.\n",
        "You learn enough math to use models responsibly.\n",
        "\n",
        "ML Algorithms\n",
        "Begin with linear and logistic regression baselines.\n",
        "Move to trees and ensembles for nonlinear structure.\n",
        "Try clustering for unsupervised pattern discovery.\n",
        "Use cross-validation to compare model families.\n",
        "Tune hyperparameters only after strong baselines.\n",
        "\n",
        "MLOps Basics\n",
        "Track experiments with simple run identifiers.\n",
        "Package code for predictable training and inference.\n",
        "Capture environment details for reproducibility.\n",
        "Automate small checks in a lightweight CI step.\n",
        "Log decisions and metrics for future audits.\n",
        "\n",
        "Case Studies\n",
        "Start with a crisp problem statement and success metric.\n",
        "Explore data visually to form testable hypotheses.\n",
        "Engineer features grounded in domain intuition.\n",
        "Validate with appropriate temporal splits when needed.\n",
        "Present tradeoffs and a pragmatic recommendation.\n",
        "\n",
        "Communication\n",
        "Use plain language in reports and presentations.\n",
        "Prefer few clear plots over many noisy ones.\n",
        "Explain why a metric was chosen for the task.\n",
        "State assumptions and limitations openly.\n",
        "Outline next steps with realistic timelines.\n",
        "\n",
        "Enrollment Flexibility\n",
        "Mid-month joins are supported by rolling validity.\n",
        "Renewals occur thirty days after your payment date.\n",
        "Access continues until the current cycle ends.\n",
        "Rejoining later restores your dashboard promptly.\n",
        "You can learn at a pace that fits your schedule.\n",
        "\n",
        "Support Channels\n",
        "Email support for payment or access issues.\n",
        "Include registered email and phone in messages.\n",
        "Attach relevant screenshots for context.\n",
        "Expect confirmation and estimated response windows.\n",
        "Escalations are available for unresolved cases.\n",
        "\n",
        "What’s Not Included\n",
        "Deep Learning is outside the current scope.\n",
        "NLP topics are not covered in this program.\n",
        "Placement guarantees are not offered by the team.\n",
        "Lifetime access is not provided due to low fees.\n",
        "Advanced research topics are out of scope here.\n",
        "\n",
        "After Course Access\n",
        "After completing seven payments you keep access until the stated end date.\n",
        "Final access windows are communicated near course completion.\n",
        "Policies may update; refer to official pages for changes.\n",
        "Timelines align with the published DSMP cohort information.\n",
        "Use the dashboard to check your current validity dates.\n",
        "\n",
        "Study Habits\n",
        "Block time after each class to review notes.\n",
        "Rewatch complex parts of recordings at higher speed.\n",
        "Practice SQL and Pandas daily for fluency.\n",
        "Summarize each module in your own words.\n",
        "Share doubts early through the form.\n",
        "\n",
        "Quality and Integrity\n",
        "Cite data sources when using external datasets.\n",
        "Avoid leaking information across data splits.\n",
        "Prefer interpretable baselines before complex stacks.\n",
        "Use calibration where thresholds matter to outcomes.\n",
        "Keep feedback loops open with mentors and peers.\n",
        "\n",
        "Community and Mentorship\n",
        "Portfolio sessions cover project curation and impact framing.\n",
        "Soft-skill exercises include STAR answers and mock interviews.\n",
        "Mentor talks reveal real constraints from industry work.\n",
        "Networking tips center on targeted outreach and follow-ups.\n",
        "Job strategies emphasize ATS alignment to job descriptions.\n",
        "\n",
        "Admin Reminders\n",
        "All payments are processed on the official website.\n",
        "Refunds are handled only within the seven-day window.\n",
        "Schedules are updated in the shared Google Sheet.\n",
        "Official updates are sent via registered email.\n",
        "Keep your profile details accurate in the dashboard.\n",
        "\n",
        "Contact\n",
        "For payments and access, write to nitish.campusx@gmail.com.\n",
        "Use clear subject lines describing your issue briefly.\n",
        "Include your registered email and transaction details.\n",
        "Do not share sensitive information in emails.\n",
        "Expect a response with next steps and timelines.\n",
        "\n",
        "Wrapping Up\n",
        "The DSMP focuses on solid DS foundations and practical ML.\n",
        "You will learn Python, SQL, Maths, and core ML methods.\n",
        "MLOps adds tracking and simple deployment discipline.\n",
        "Case studies tie methods to decisions stakeholders care about.\n",
        "Recordings, rolling validity, and guidance keep learning flexible.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "878772b7-424c-41c3-e42a-4b2174b22c7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "754"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "1cc7eb14-ecfe-430a-8fa5-d289911ed73b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[83, 2],\n",
              " [83, 2, 55],\n",
              " [84, 55],\n",
              " [84, 55, 268],\n",
              " [84, 55, 268, 9],\n",
              " [84, 55, 268, 9, 85],\n",
              " [84, 55, 268, 9, 85, 144],\n",
              " [84, 55, 268, 9, 85, 144, 145],\n",
              " [84, 55, 268, 9, 85, 144, 145, 24],\n",
              " [84, 55, 268, 9, 85, 144, 145, 24, 146],\n",
              " [84, 55, 268, 9, 85, 144, 145, 24, 146, 269],\n",
              " [84, 55, 268, 9, 85, 144, 145, 24, 146, 269, 270],\n",
              " [84, 55, 268, 9, 85, 144, 145, 24, 146, 269, 270, 86],\n",
              " [2, 271],\n",
              " [2, 271, 272],\n",
              " [2, 271, 272, 25],\n",
              " [2, 271, 272, 25, 2],\n",
              " [2, 271, 272, 25, 2, 87],\n",
              " [2, 271, 272, 25, 2, 87, 14],\n",
              " [2, 271, 272, 25, 2, 87, 14, 26],\n",
              " [2, 271, 272, 25, 2, 87, 14, 26, 88],\n",
              " [2, 273],\n",
              " [2, 273, 274],\n",
              " [2, 273, 274, 147],\n",
              " [2, 273, 274, 147, 56],\n",
              " [2, 273, 274, 147, 56, 26],\n",
              " [2, 273, 274, 147, 56, 26, 88],\n",
              " [2, 273, 274, 147, 56, 26, 88, 14],\n",
              " [2, 273, 274, 147, 56, 26, 88, 14, 146],\n",
              " [2, 273, 274, 147, 56, 26, 88, 14, 146, 275],\n",
              " [7, 15],\n",
              " [7, 15, 148],\n",
              " [7, 15, 148, 276],\n",
              " [7, 15, 148, 276, 277],\n",
              " [7, 15, 148, 276, 277, 278],\n",
              " [7, 15, 148, 276, 277, 278, 3],\n",
              " [7, 15, 148, 276, 277, 278, 3, 9],\n",
              " [7, 15, 148, 276, 277, 278, 3, 9, 279],\n",
              " [7, 15, 148, 276, 277, 278, 3, 9, 279, 280],\n",
              " [7, 15, 148, 276, 277, 278, 3, 9, 279, 280, 4],\n",
              " [7, 15, 148, 276, 277, 278, 3, 9, 279, 280, 4, 42],\n",
              " [89, 43],\n",
              " [89, 43, 23],\n",
              " [89, 43, 23, 5],\n",
              " [89, 43, 23, 5, 281],\n",
              " [89, 43, 23, 5, 281, 3],\n",
              " [89, 43, 23, 5, 281, 3, 90],\n",
              " [89, 43, 23, 5, 281, 3, 90, 282],\n",
              " [44, 18],\n",
              " [44, 18, 149],\n",
              " [44, 18, 149, 10],\n",
              " [44, 18, 149, 10, 6],\n",
              " [44, 18, 149, 10, 6, 19],\n",
              " [44, 18, 149, 10, 6, 19, 16],\n",
              " [44, 18, 149, 10, 6, 19, 16, 91],\n",
              " [150, 43],\n",
              " [150, 43, 23],\n",
              " [150, 43, 23, 92],\n",
              " [150, 43, 23, 92, 3],\n",
              " [150, 43, 23, 92, 3, 83],\n",
              " [150, 43, 23, 92, 3, 83, 283],\n",
              " [150, 43, 23, 92, 3, 83, 283, 284],\n",
              " [2, 285],\n",
              " [2, 285, 151],\n",
              " [2, 285, 151, 152],\n",
              " [2, 285, 151, 152, 10],\n",
              " [2, 285, 151, 152, 10, 91],\n",
              " [2, 285, 151, 152, 10, 91, 14],\n",
              " [2, 285, 151, 152, 10, 91, 14, 153],\n",
              " [154, 286],\n",
              " [154, 286, 93],\n",
              " [154, 286, 93, 5],\n",
              " [154, 286, 93, 5, 287],\n",
              " [154, 286, 93, 5, 287, 4],\n",
              " [154, 286, 93, 5, 287, 4, 288],\n",
              " [154, 286, 93, 5, 287, 4, 288, 1],\n",
              " [154, 286, 93, 5, 287, 4, 288, 1, 42],\n",
              " [154, 286, 93, 5, 287, 4, 288, 1, 42, 32],\n",
              " [154, 286, 93, 5, 287, 4, 288, 1, 42, 32, 57],\n",
              " [155, 94],\n",
              " [155, 94, 289],\n",
              " [155, 94, 289, 156],\n",
              " [155, 94, 289, 156, 290],\n",
              " [155, 94, 289, 156, 290, 12],\n",
              " [155, 94, 289, 156, 290, 12, 4],\n",
              " [155, 94, 289, 156, 290, 12, 4, 95],\n",
              " [155, 94, 289, 156, 290, 12, 4, 95, 18],\n",
              " [155, 94, 289, 156, 290, 12, 4, 95, 18, 157],\n",
              " [155, 94, 289, 156, 290, 12, 4, 95, 18, 157, 27],\n",
              " [96, 291],\n",
              " [2, 96],\n",
              " [2, 96, 292],\n",
              " [2, 96, 292, 45],\n",
              " [2, 96, 292, 45, 158],\n",
              " [2, 96, 292, 45, 158, 3],\n",
              " [2, 96, 292, 45, 158, 3, 159],\n",
              " [2, 96, 292, 45, 158, 3, 159, 160],\n",
              " [7, 58],\n",
              " [7, 58, 59],\n",
              " [7, 58, 59, 45],\n",
              " [7, 58, 59, 45, 161],\n",
              " [7, 58, 59, 45, 161, 152],\n",
              " [7, 58, 59, 45, 161, 152, 10],\n",
              " [7, 58, 59, 45, 161, 152, 10, 20],\n",
              " [7, 58, 59, 45, 161, 152, 10, 20, 162],\n",
              " [7, 58, 59, 45, 161, 152, 10, 20, 162, 163],\n",
              " [20, 97],\n",
              " [20, 97, 293],\n",
              " [20, 97, 293, 164],\n",
              " [20, 97, 293, 164, 11],\n",
              " [20, 97, 293, 164, 11, 165],\n",
              " [20, 97, 293, 164, 11, 165, 1],\n",
              " [20, 97, 293, 164, 11, 165, 1, 294],\n",
              " [20, 97, 293, 164, 11, 165, 1, 294, 8],\n",
              " [20, 97, 293, 164, 11, 165, 1, 294, 8, 20],\n",
              " [33, 3],\n",
              " [33, 3, 20],\n",
              " [33, 3, 20, 162],\n",
              " [33, 3, 20, 162, 166],\n",
              " [33, 3, 20, 162, 166, 60],\n",
              " [33, 3, 20, 162, 166, 60, 1],\n",
              " [33, 3, 20, 162, 166, 60, 1, 34],\n",
              " [33, 3, 20, 162, 166, 60, 1, 34, 98],\n",
              " [61, 3],\n",
              " [61, 3, 295],\n",
              " [61, 3, 295, 46],\n",
              " [61, 3, 295, 46, 296],\n",
              " [61, 3, 295, 46, 296, 62],\n",
              " [61, 3, 295, 46, 296, 62, 167],\n",
              " [61, 3, 295, 46, 296, 62, 167, 1],\n",
              " [61, 3, 295, 46, 296, 62, 167, 1, 297],\n",
              " [61, 3, 295, 46, 296, 62, 167, 1, 297, 298],\n",
              " [28, 99],\n",
              " [28, 99, 29],\n",
              " [28, 99, 29, 299],\n",
              " [28, 99, 29, 299, 1],\n",
              " [28, 99, 29, 299, 1, 168],\n",
              " [28, 99, 29, 299, 1, 168, 300],\n",
              " [47, 28],\n",
              " [47, 28, 100],\n",
              " [47, 28, 100, 11],\n",
              " [47, 28, 100, 11, 101],\n",
              " [47, 28, 100, 11, 101, 63],\n",
              " [47, 28, 100, 11, 101, 63, 1],\n",
              " [47, 28, 100, 11, 101, 63, 1, 301],\n",
              " [47, 28, 100, 11, 101, 63, 1, 301, 302],\n",
              " [64, 169],\n",
              " [64, 169, 303],\n",
              " [64, 169, 303, 102],\n",
              " [64, 169, 303, 102, 170],\n",
              " [64, 169, 303, 102, 170, 1],\n",
              " [64, 169, 303, 102, 170, 1, 65],\n",
              " [64, 169, 303, 102, 170, 1, 65, 171],\n",
              " [64, 169, 303, 102, 170, 1, 65, 171, 304],\n",
              " [66, 67],\n",
              " [66, 67, 305],\n",
              " [66, 67, 305, 172],\n",
              " [66, 67, 305, 172, 103],\n",
              " [66, 67, 305, 172, 103, 306],\n",
              " [66, 67, 305, 172, 103, 306, 1],\n",
              " [66, 67, 305, 172, 103, 306, 1, 68],\n",
              " [173, 46],\n",
              " [173, 46, 1],\n",
              " [173, 46, 1, 174],\n",
              " [173, 46, 1, 174, 5],\n",
              " [173, 46, 1, 174, 5, 13],\n",
              " [173, 46, 1, 174, 5, 13, 307],\n",
              " [173, 46, 1, 174, 5, 13, 307, 25],\n",
              " [173, 46, 1, 174, 5, 13, 307, 25, 84],\n",
              " [173, 46, 1, 174, 5, 13, 307, 25, 84, 308],\n",
              " [104, 1],\n",
              " [104, 1, 175],\n",
              " [7, 15],\n",
              " [7, 15, 105],\n",
              " [7, 15, 105, 309],\n",
              " [7, 15, 105, 309, 96],\n",
              " [7, 15, 105, 309, 96, 11],\n",
              " [7, 15, 105, 309, 96, 11, 2],\n",
              " [7, 15, 105, 309, 96, 11, 2, 30],\n",
              " [7, 15, 105, 309, 96, 11, 2, 30, 35],\n",
              " [7, 15, 105, 309, 96, 11, 2, 30, 35, 310],\n",
              " [2, 85],\n",
              " [2, 85, 311],\n",
              " [2, 85, 311, 14],\n",
              " [2, 85, 311, 14, 106],\n",
              " [2, 85, 311, 14, 106, 36],\n",
              " [2, 85, 311, 14, 106, 36, 9],\n",
              " [2, 85, 311, 14, 106, 36, 9, 312],\n",
              " [2, 85, 311, 14, 106, 36, 9, 312, 176],\n",
              " [2, 85, 311, 14, 106, 36, 9, 312, 176, 48],\n",
              " [30, 37],\n",
              " [30, 37, 5],\n",
              " [30, 37, 5, 177],\n",
              " [30, 37, 5, 177, 69],\n",
              " [30, 37, 5, 177, 69, 36],\n",
              " [30, 37, 5, 177, 69, 36, 2],\n",
              " [30, 37, 5, 177, 69, 36, 2, 35],\n",
              " [30, 37, 5, 177, 69, 36, 2, 35, 70],\n",
              " [178, 71],\n",
              " [178, 71, 5],\n",
              " [178, 71, 5, 179],\n",
              " [178, 71, 5, 179, 38],\n",
              " [178, 71, 5, 179, 38, 39],\n",
              " [178, 71, 5, 179, 38, 39, 180],\n",
              " [178, 71, 5, 179, 38, 39, 180, 44],\n",
              " [19, 12],\n",
              " [19, 12, 313],\n",
              " [19, 12, 313, 18],\n",
              " [19, 12, 313, 18, 49],\n",
              " [19, 12, 313, 18, 49, 1],\n",
              " [19, 12, 313, 18, 49, 1, 2],\n",
              " [19, 12, 313, 18, 49, 1, 2, 107],\n",
              " [19, 12, 313, 18, 49, 1, 2, 107, 40],\n",
              " [43, 23],\n",
              " [72, 7],\n",
              " [72, 7, 314],\n",
              " [72, 7, 314, 9],\n",
              " [72, 7, 314, 9, 44],\n",
              " [72, 7, 314, 9, 44, 7],\n",
              " [72, 7, 314, 9, 44, 7, 15],\n",
              " [72, 7, 314, 9, 44, 7, 15, 315],\n",
              " [72, 7, 314, 9, 44, 7, 15, 315, 2],\n",
              " [72, 7, 314, 9, 44, 7, 15, 315, 2, 316],\n",
              " [72, 7, 314, 9, 44, 7, 15, 315, 2, 316, 90],\n",
              " [317, 23],\n",
              " [317, 23, 181],\n",
              " [317, 23, 181, 318],\n",
              " [317, 23, 181, 318, 108],\n",
              " [317, 23, 181, 318, 108, 319],\n",
              " [317, 23, 181, 318, 108, 319, 1],\n",
              " [317, 23, 181, 318, 108, 319, 1, 320],\n",
              " [317, 23, 181, 318, 108, 319, 1, 320, 321],\n",
              " [322, 5],\n",
              " [322, 5, 323],\n",
              " [322, 5, 323, 10],\n",
              " [322, 5, 323, 10, 324],\n",
              " [322, 5, 323, 10, 324, 8],\n",
              " [322, 5, 323, 10, 324, 8, 153],\n",
              " [322, 5, 323, 10, 324, 8, 153, 325],\n",
              " [326, 9],\n",
              " [326, 9, 50],\n",
              " [326, 9, 50, 14],\n",
              " [326, 9, 50, 14, 327],\n",
              " [326, 9, 50, 14, 327, 24],\n",
              " [326, 9, 50, 14, 327, 24, 2],\n",
              " [326, 9, 50, 14, 327, 24, 2, 182],\n",
              " [326, 9, 50, 14, 327, 24, 2, 182, 25],\n",
              " [326, 9, 50, 14, 327, 24, 2, 182, 25, 2],\n",
              " [326, 9, 50, 14, 327, 24, 2, 182, 25, 2, 44],\n",
              " [183, 109],\n",
              " [183, 109, 5],\n",
              " [183, 109, 5, 328],\n",
              " [183, 109, 5, 328, 11],\n",
              " [183, 109, 5, 328, 11, 2],\n",
              " [183, 109, 5, 328, 11, 2, 106],\n",
              " [183, 109, 5, 328, 11, 2, 106, 48],\n",
              " [12, 1],\n",
              " [12, 1, 27],\n",
              " [6, 144],\n",
              " [6, 144, 14],\n",
              " [6, 144, 14, 329],\n",
              " [6, 144, 14, 329, 3],\n",
              " [6, 144, 14, 329, 3, 110],\n",
              " [6, 144, 14, 329, 3, 110, 73],\n",
              " [6, 144, 14, 329, 3, 110, 73, 32],\n",
              " [6, 144, 14, 329, 3, 110, 73, 32, 330],\n",
              " [6, 144, 14, 329, 3, 110, 73, 32, 330, 50],\n",
              " [184, 331],\n",
              " [184, 331, 6],\n",
              " [184, 331, 6, 12],\n",
              " [184, 331, 6, 12, 34],\n",
              " [184, 331, 6, 12, 34, 51],\n",
              " [184, 331, 6, 12, 34, 51, 332],\n",
              " [184, 331, 6, 12, 34, 51, 332, 110],\n",
              " [184, 331, 6, 12, 34, 51, 332, 110, 73],\n",
              " [157, 333],\n",
              " [157, 333, 334],\n",
              " [157, 333, 334, 185],\n",
              " [157, 333, 334, 185, 95],\n",
              " [157, 333, 334, 185, 95, 180],\n",
              " [157, 333, 334, 185, 95, 180, 186],\n",
              " [157, 333, 334, 185, 95, 180, 186, 335],\n",
              " [157, 333, 334, 185, 95, 180, 186, 335, 336],\n",
              " [72, 6],\n",
              " [72, 6, 27],\n",
              " [72, 6, 27, 337],\n",
              " [72, 6, 27, 337, 7],\n",
              " [72, 6, 27, 337, 7, 58],\n",
              " [72, 6, 27, 337, 7, 58, 187],\n",
              " [72, 6, 27, 337, 7, 58, 187, 4],\n",
              " [72, 6, 27, 337, 7, 58, 187, 4, 338],\n",
              " [72, 6, 27, 337, 7, 58, 187, 4, 338, 4],\n",
              " [72, 6, 27, 337, 7, 58, 187, 4, 338, 4, 339],\n",
              " [155, 11],\n",
              " [155, 11, 188],\n",
              " [155, 11, 188, 52],\n",
              " [155, 11, 188, 52, 340],\n",
              " [155, 11, 188, 52, 340, 6],\n",
              " [155, 11, 188, 52, 340, 6, 111],\n",
              " [155, 11, 188, 52, 340, 6, 111, 341],\n",
              " [155, 11, 188, 52, 340, 6, 111, 341, 4],\n",
              " [155, 11, 188, 52, 340, 6, 111, 341, 4, 189],\n",
              " [155, 11, 188, 52, 340, 6, 111, 341, 4, 189, 52],\n",
              " [112, 190],\n",
              " [9, 26],\n",
              " [9, 26, 191],\n",
              " [9, 26, 191, 112],\n",
              " [9, 26, 191, 112, 34],\n",
              " [9, 26, 191, 112, 34, 192],\n",
              " [9, 26, 191, 112, 34, 192, 32],\n",
              " [9, 26, 191, 112, 34, 192, 32, 6],\n",
              " [9, 26, 191, 112, 34, 192, 32, 6, 21],\n",
              " [9, 26, 191, 112, 34, 192, 32, 6, 21, 52],\n",
              " [113, 342],\n",
              " [113, 342, 16],\n",
              " [113, 342, 16, 26],\n",
              " [113, 342, 16, 26, 73],\n",
              " [113, 342, 16, 26, 73, 5],\n",
              " [113, 342, 16, 26, 73, 5, 13],\n",
              " [113, 342, 16, 26, 73, 5, 13, 343],\n",
              " [344, 6],\n",
              " [344, 6, 167],\n",
              " [344, 6, 167, 193],\n",
              " [344, 6, 167, 193, 4],\n",
              " [344, 6, 167, 193, 4, 345],\n",
              " [344, 6, 167, 193, 4, 345, 346],\n",
              " [344, 6, 167, 193, 4, 345, 346, 38],\n",
              " [344, 6, 167, 193, 4, 345, 346, 38, 2],\n",
              " [344, 6, 167, 193, 4, 345, 346, 38, 2, 34],\n",
              " [344, 6, 167, 193, 4, 345, 346, 38, 2, 34, 347],\n",
              " [114, 22],\n",
              " [114, 22, 72],\n",
              " [114, 22, 72, 7],\n",
              " [114, 22, 72, 7, 187],\n",
              " [114, 22, 72, 7, 187, 74],\n",
              " [114, 22, 72, 7, 187, 74, 348],\n",
              " [114, 22, 72, 7, 187, 74, 348, 9],\n",
              " [114, 22, 72, 7, 187, 74, 348, 9, 112],\n",
              " [114, 22, 72, 7, 187, 74, 348, 9, 112, 349],\n",
              " [113, 350],\n",
              " [113, 350, 4],\n",
              " [113, 350, 4, 2],\n",
              " [113, 350, 4, 2, 351],\n",
              " [113, 350, 4, 2, 351, 21],\n",
              " [113, 350, 4, 2, 351, 21, 115],\n",
              " [113, 350, 4, 2, 351, 21, 115, 190],\n",
              " [113, 350, 4, 2, 351, 21, 115, 190, 352],\n",
              " [85, 37],\n",
              " [85, 37, 116],\n",
              " [85, 37, 116, 75],\n",
              " [85, 37, 116, 75, 177],\n",
              " [85, 37, 116, 75, 177, 11],\n",
              " [85, 37, 116, 75, 177, 11, 2],\n",
              " [85, 37, 116, 75, 177, 11, 2, 30],\n",
              " [85, 37, 116, 75, 177, 11, 2, 30, 70],\n",
              " [194, 13],\n",
              " [194, 13, 195],\n",
              " [194, 13, 195, 36],\n",
              " [194, 13, 195, 36, 353],\n",
              " [194, 13, 195, 36, 353, 354],\n",
              " [194, 13, 195, 36, 353, 354, 104],\n",
              " [194, 13, 195, 36, 353, 354, 104, 53],\n",
              " [194, 13, 195, 36, 353, 354, 104, 53, 355],\n",
              " [194, 13, 195, 36, 353, 354, 104, 53, 355, 196],\n",
              " [356, 5],\n",
              " [356, 5, 357],\n",
              " [356, 5, 357, 16],\n",
              " [356, 5, 357, 16, 197],\n",
              " [356, 5, 357, 16, 197, 21],\n",
              " [356, 5, 357, 16, 197, 21, 358],\n",
              " [198, 21],\n",
              " [198, 21, 117],\n",
              " [198, 21, 117, 15],\n",
              " [198, 21, 117, 15, 75],\n",
              " [198, 21, 117, 15, 75, 359],\n",
              " [198, 21, 117, 15, 75, 359, 51],\n",
              " [198, 21, 117, 15, 75, 359, 51, 41],\n",
              " [29, 6],\n",
              " [29, 6, 76],\n",
              " [29, 6, 76, 41],\n",
              " [29, 6, 76, 41, 1],\n",
              " [29, 6, 76, 41, 1, 199],\n",
              " [29, 6, 76, 41, 1, 199, 360],\n",
              " [29, 6, 76, 41, 1, 199, 360, 54],\n",
              " [29, 6, 76, 41, 1, 199, 360, 54, 361],\n",
              " [29, 6, 76, 41, 1, 199, 360, 54, 361, 22],\n",
              " [362, 1],\n",
              " [362, 1, 363],\n",
              " [160, 32],\n",
              " [160, 32, 154],\n",
              " [160, 32, 154, 364],\n",
              " [160, 32, 154, 364, 365],\n",
              " [160, 32, 154, 364, 365, 15],\n",
              " [160, 32, 154, 364, 365, 15, 148],\n",
              " [160, 32, 154, 364, 365, 15, 148, 366],\n",
              " [2, 35],\n",
              " [2, 35, 192],\n",
              " [2, 35, 192, 32],\n",
              " [2, 35, 192, 32, 45],\n",
              " [2, 35, 192, 32, 45, 57],\n",
              " [2, 35, 192, 32, 45, 57, 1],\n",
              " [2, 35, 192, 32, 45, 57, 1, 200],\n",
              " [2, 35, 192, 32, 45, 57, 1, 200, 367],\n",
              " [7, 15],\n",
              " [7, 15, 368],\n",
              " [7, 15, 368, 10],\n",
              " [7, 15, 368, 10, 94],\n",
              " [7, 15, 368, 10, 94, 86],\n",
              " [7, 15, 368, 10, 94, 86, 1],\n",
              " [7, 15, 368, 10, 94, 86, 1, 201],\n",
              " [7, 15, 368, 10, 94, 86, 1, 201, 8],\n",
              " [7, 15, 368, 10, 94, 86, 1, 201, 8, 18],\n",
              " [6, 19],\n",
              " [6, 19, 369],\n",
              " [6, 19, 369, 370],\n",
              " [6, 19, 369, 370, 16],\n",
              " [6, 19, 369, 370, 16, 197],\n",
              " [6, 19, 369, 370, 16, 197, 21],\n",
              " [371, 49],\n",
              " [371, 49, 74],\n",
              " [371, 49, 74, 7],\n",
              " [371, 49, 74, 7, 372],\n",
              " [371, 49, 74, 7, 372, 2],\n",
              " [371, 49, 74, 7, 372, 2, 373],\n",
              " [371, 49, 74, 7, 372, 2, 373, 374],\n",
              " [107, 22],\n",
              " [7, 15],\n",
              " [7, 15, 375],\n",
              " [7, 15, 375, 9],\n",
              " [7, 15, 375, 9, 107],\n",
              " [7, 15, 375, 9, 107, 40],\n",
              " [7, 15, 375, 9, 107, 40, 36],\n",
              " [7, 15, 375, 9, 107, 40, 36, 2],\n",
              " [7, 15, 375, 9, 107, 40, 36, 2, 19],\n",
              " [2, 202],\n",
              " [2, 202, 109],\n",
              " [2, 202, 109, 108],\n",
              " [2, 202, 109, 108, 11],\n",
              " [2, 202, 109, 108, 11, 108],\n",
              " [2, 202, 109, 108, 11, 108, 118],\n",
              " [2, 202, 109, 108, 11, 108, 118, 376],\n",
              " [2, 202, 109, 108, 11, 108, 118, 376, 3],\n",
              " [2, 202, 109, 108, 11, 108, 118, 376, 3, 119],\n",
              " [2, 202, 109, 108, 11, 108, 118, 376, 3, 119, 117],\n",
              " [95, 193],\n",
              " [95, 193, 203],\n",
              " [95, 193, 203, 15],\n",
              " [95, 193, 203, 15, 156],\n",
              " [95, 193, 203, 15, 156, 75],\n",
              " [95, 193, 203, 15, 156, 75, 377],\n",
              " [95, 193, 203, 15, 156, 75, 377, 204],\n",
              " [95, 193, 203, 15, 156, 75, 377, 204, 2],\n",
              " [95, 193, 203, 15, 156, 75, 377, 204, 2, 40],\n",
              " [95, 193, 203, 15, 156, 75, 377, 204, 2, 40, 378],\n",
              " [379, 205],\n",
              " [379, 205, 53],\n",
              " [379, 205, 53, 120],\n",
              " [379, 205, 53, 120, 4],\n",
              " [379, 205, 53, 120, 4, 206],\n",
              " [379, 205, 53, 120, 4, 206, 207],\n",
              " [379, 205, 53, 120, 4, 206, 207, 380],\n",
              " [121, 208],\n",
              " [121, 208, 5],\n",
              " [121, 208, 5, 209],\n",
              " [121, 208, 5, 209, 16],\n",
              " [121, 208, 5, 209, 16, 40],\n",
              " [121, 208, 5, 209, 16, 40, 210],\n",
              " [381, 211],\n",
              " [7, 116],\n",
              " [7, 116, 159],\n",
              " [7, 116, 159, 382],\n",
              " [7, 116, 159, 382, 147],\n",
              " [7, 116, 159, 382, 147, 21],\n",
              " [7, 116, 159, 382, 147, 21, 56],\n",
              " [7, 116, 159, 382, 147, 21, 56, 26],\n",
              " [7, 116, 159, 382, 147, 21, 56, 26, 88],\n",
              " [7, 116],\n",
              " [7, 116, 383],\n",
              " [7, 116, 383, 89],\n",
              " [7, 116, 383, 89, 35],\n",
              " [7, 116, 383, 89, 35, 122],\n",
              " [7, 116, 383, 89, 35, 122, 4],\n",
              " [7, 116, 383, 89, 35, 122, 4, 384],\n",
              " [385, 5],\n",
              " [385, 5, 386],\n",
              " [385, 5, 386, 4],\n",
              " [385, 5, 386, 4, 93],\n",
              " [385, 5, 386, 4, 93, 387],\n",
              " [385, 5, 386, 4, 93, 387, 388],\n",
              " [385, 5, 386, 4, 93, 387, 388, 389],\n",
              " [385, 5, 386, 4, 93, 387, 388, 389, 211],\n",
              " [122, 212],\n",
              " [122, 212, 390],\n",
              " [122, 212, 390, 391],\n",
              " [122, 212, 390, 391, 123],\n",
              " [122, 212, 390, 391, 123, 392],\n",
              " [122, 212, 390, 391, 123, 392, 213],\n",
              " [31, 210],\n",
              " [31, 210, 49],\n",
              " [31, 210, 49, 214],\n",
              " [31, 210, 49, 214, 1],\n",
              " [31, 210, 49, 214, 1, 393],\n",
              " [31, 210, 49, 214, 1, 393, 394],\n",
              " [77, 124],\n",
              " [77, 124],\n",
              " [77, 124, 395],\n",
              " [77, 124, 395, 13],\n",
              " [77, 124, 395, 13, 396],\n",
              " [77, 124, 395, 13, 396, 9],\n",
              " [77, 124, 395, 13, 396, 9, 77],\n",
              " [77, 124, 395, 13, 396, 9, 77, 397],\n",
              " [78, 398],\n",
              " [78, 398, 53],\n",
              " [78, 398, 53, 125],\n",
              " [78, 398, 53, 125, 5],\n",
              " [78, 398, 53, 125, 5, 13],\n",
              " [78, 398, 53, 125, 5, 13, 399],\n",
              " [78, 398, 53, 125, 5, 13, 399, 51],\n",
              " [78, 398, 53, 125, 5, 13, 399, 51, 2],\n",
              " [78, 398, 53, 125, 5, 13, 399, 51, 2, 55],\n",
              " [124, 166],\n",
              " [124, 166, 215],\n",
              " [124, 166, 215, 400],\n",
              " [124, 166, 215, 400, 1],\n",
              " [124, 166, 215, 400, 1, 401],\n",
              " [124, 166, 215, 400, 1, 401, 79],\n",
              " [216, 217],\n",
              " [216, 217, 23],\n",
              " [216, 217, 23, 218],\n",
              " [216, 217, 23, 218, 219],\n",
              " [216, 217, 23, 218, 219, 1],\n",
              " [216, 217, 23, 218, 219, 1, 125],\n",
              " [220, 23],\n",
              " [220, 23, 402],\n",
              " [220, 23, 402, 221],\n",
              " [220, 23, 402, 221, 403],\n",
              " [220, 23, 402, 221, 403, 404],\n",
              " [220, 23, 402, 221, 403, 404, 1],\n",
              " [220, 23, 402, 221, 403, 404, 1, 222],\n",
              " [78, 405],\n",
              " [78, 405, 223],\n",
              " [78, 405, 223, 126],\n",
              " [78, 405, 223, 126, 224],\n",
              " [78, 405, 223, 126, 224, 406],\n",
              " [78, 405, 223, 126, 224, 406, 1],\n",
              " [78, 405, 223, 126, 224, 406, 1, 225],\n",
              " [7, 407],\n",
              " [7, 407, 127],\n",
              " [7, 407, 127, 79],\n",
              " [7, 407, 127, 79, 13],\n",
              " [7, 407, 127, 79, 13, 408],\n",
              " [7, 407, 127, 79, 13, 408, 226],\n",
              " [186, 409],\n",
              " [45, 158],\n",
              " [45, 158, 126],\n",
              " [45, 158, 126, 410],\n",
              " [45, 158, 126, 410, 411],\n",
              " [45, 158, 126, 410, 411, 412],\n",
              " [45, 158, 126, 410, 411, 412, 1],\n",
              " [45, 158, 126, 410, 411, 412, 1, 98],\n",
              " [161, 3],\n",
              " [161, 3, 227],\n",
              " [161, 3, 227, 29],\n",
              " [161, 3, 227, 29, 413],\n",
              " [161, 3, 227, 29, 413, 128],\n",
              " [161, 3, 227, 29, 413, 128, 1],\n",
              " [161, 3, 227, 29, 413, 128, 1, 414],\n",
              " [20, 97],\n",
              " [20, 97, 100],\n",
              " [20, 97, 100, 11],\n",
              " [20, 97, 100, 11, 415],\n",
              " [20, 97, 100, 11, 415, 20],\n",
              " [20, 97, 100, 11, 415, 20, 1],\n",
              " [20, 97, 100, 11, 415, 20, 1, 416],\n",
              " [20, 97, 100, 11, 415, 20, 1, 416, 165],\n",
              " [33, 129],\n",
              " [33, 129, 200],\n",
              " [33, 129, 200, 417],\n",
              " [33, 129, 200, 417, 8],\n",
              " [33, 129, 200, 417, 8, 60],\n",
              " [33, 129, 200, 417, 8, 60, 1],\n",
              " [33, 129, 200, 417, 8, 60, 1, 418],\n",
              " [61, 3],\n",
              " [61, 3, 28],\n",
              " [61, 3, 28, 419],\n",
              " [61, 3, 28, 419, 62],\n",
              " [61, 3, 28, 419, 62, 3],\n",
              " [61, 3, 28, 419, 62, 3, 228],\n",
              " [61, 3, 28, 419, 62, 3, 228, 1],\n",
              " [61, 3, 28, 419, 62, 3, 228, 1, 229],\n",
              " [99, 29],\n",
              " [99, 29, 230],\n",
              " [99, 29, 230, 130],\n",
              " [99, 29, 230, 130, 231],\n",
              " [99, 29, 230, 130, 231, 1],\n",
              " [99, 29, 230, 130, 231, 1, 232],\n",
              " [47, 28],\n",
              " [47, 28, 420],\n",
              " [47, 28, 420, 101],\n",
              " [47, 28, 420, 101, 1],\n",
              " [47, 28, 420, 101, 1, 63],\n",
              " [47, 28, 420, 101, 1, 63, 421],\n",
              " [64, 169],\n",
              " [64, 169, 102],\n",
              " [64, 169, 102, 170],\n",
              " [64, 169, 102, 170, 1],\n",
              " [64, 169, 102, 170, 1, 422],\n",
              " [66, 67],\n",
              " [66, 67, 423],\n",
              " [66, 67, 423, 131],\n",
              " [66, 67, 423, 131, 4],\n",
              " [66, 67, 423, 131, 4, 103],\n",
              " [66, 67, 423, 131, 4, 103, 68],\n",
              " [18, 1],\n",
              " [18, 1, 19],\n",
              " [18, 5],\n",
              " [18, 5, 6],\n",
              " [18, 5, 6, 233],\n",
              " [18, 5, 6, 233, 424],\n",
              " [18, 5, 6, 233, 424, 3],\n",
              " [18, 5, 6, 233, 424, 3, 425],\n",
              " [18, 5, 6, 233, 424, 3, 425, 234],\n",
              " [426, 149],\n",
              " [426, 149, 10],\n",
              " [426, 149, 10, 2],\n",
              " [426, 149, 10, 2, 19],\n",
              " [426, 149, 10, 2, 19, 115],\n",
              " [426, 149, 10, 2, 19, 115, 2],\n",
              " [426, 149, 10, 2, 19, 115, 2, 27],\n",
              " [426, 149, 10, 2, 19, 115, 2, 27, 427],\n",
              " [428, 175],\n",
              " [428, 175, 5],\n",
              " [428, 175, 5, 429],\n",
              " [428, 175, 5, 429, 132],\n",
              " [428, 175, 5, 429, 132, 430],\n",
              " [7, 15],\n",
              " [7, 15, 235],\n",
              " [7, 15, 235, 431],\n",
              " [7, 15, 235, 431, 432],\n",
              " [7, 15, 235, 431, 432, 24],\n",
              " [7, 15, 235, 431, 432, 24, 6],\n",
              " [7, 15, 235, 431, 432, 24, 6, 236],\n",
              " [7, 15, 235, 431, 432, 24, 6, 236, 237],\n",
              " [31, 433],\n",
              " [31, 433, 49],\n",
              " [31, 433, 49, 434],\n",
              " [31, 433, 49, 434, 4],\n",
              " [31, 433, 49, 434, 4, 39],\n",
              " [31, 433, 49, 434, 4, 39, 133],\n",
              " [31, 433, 49, 434, 4, 39, 133, 435],\n",
              " [150, 234],\n",
              " [150, 234, 92],\n",
              " [150, 234, 92, 10],\n",
              " [150, 234, 92, 10, 2],\n",
              " [150, 234, 92, 10, 2, 437],\n",
              " [150, 234, 92, 10, 2, 437, 438],\n",
              " [150, 234, 92, 10, 2, 437, 438, 238],\n",
              " [439, 42],\n",
              " [439, 42, 208],\n",
              " [439, 42, 208, 5],\n",
              " [439, 42, 208, 5, 440],\n",
              " [439, 42, 208, 5, 440, 11],\n",
              " [439, 42, 208, 5, 440, 11, 2],\n",
              " [439, 42, 208, 5, 440, 11, 2, 183],\n",
              " [439, 42, 208, 5, 440, 11, 2, 183, 48],\n",
              " [178, 71],\n",
              " [178, 71, 441],\n",
              " [178, 71, 441, 38],\n",
              " [178, 71, 441, 38, 39],\n",
              " [178, 71, 441, 38, 39, 43],\n",
              " [178, 71, 441, 38, 39, 43, 44],\n",
              " [442, 104],\n",
              " [442, 104, 239],\n",
              " [442, 104, 239, 75],\n",
              " [442, 104, 239, 75, 240],\n",
              " [442, 104, 239, 75, 240, 3],\n",
              " [442, 104, 239, 75, 240, 3, 443],\n",
              " [105, 2],\n",
              " [105, 2, 48],\n",
              " [105, 2, 48, 444],\n",
              " [105, 2, 48, 444, 3],\n",
              " [105, 2, 48, 444, 3, 188],\n",
              " [105, 2, 48, 444, 3, 188, 445],\n",
              " [105, 2, 48, 444, 3, 188, 445, 241],\n",
              " [242, 1],\n",
              " [242, 1, 233],\n",
              " [446, 195],\n",
              " [446, 195, 69],\n",
              " [446, 195, 69, 36],\n",
              " [446, 195, 69, 36, 2],\n",
              " [446, 195, 69, 36, 2, 30],\n",
              " [446, 195, 69, 36, 2, 30, 70],\n",
              " [446, 195, 69, 36, 2, 30, 70, 243],\n",
              " [244, 80],\n",
              " [244, 80, 447],\n",
              " [244, 80, 447, 53],\n",
              " [244, 80, 447, 53, 448],\n",
              " [244, 80, 447, 53, 448, 8],\n",
              " [244, 80, 447, 53, 448, 8, 449],\n",
              " [22, 58],\n",
              " [22, 58, 244],\n",
              " [22, 58, 244, 450],\n",
              " [22, 58, 244, 450, 3],\n",
              " [22, 58, 244, 450, 3, 6],\n",
              " [22, 58, 244, 450, 3, 6, 451],\n",
              " [22, 58, 244, 450, 3, 6, 451, 452],\n",
              " [17, 2],\n",
              " [17, 2, 453],\n",
              " [17, 2, 453, 71],\n",
              " [17, 2, 453, 71, 3],\n",
              " [17, 2, 453, 71, 3, 21],\n",
              " [17, 2, 453, 71, 3, 21, 454],\n",
              " [17, 2, 453, 71, 3, 21, 454, 455],\n",
              " [456, 457],\n",
              " [456, 457, 38],\n",
              " [456, 457, 38, 245],\n",
              " [456, 457, 38, 245, 9],\n",
              " [456, 457, 38, 245, 9, 134],\n",
              " [198, 93],\n",
              " [72, 458],\n",
              " [72, 458, 459],\n",
              " [72, 458, 459, 114],\n",
              " [72, 458, 459, 114, 22],\n",
              " [72, 458, 459, 114, 22, 3],\n",
              " [72, 458, 459, 114, 22, 3, 460],\n",
              " [80, 134],\n",
              " [80, 134, 246],\n",
              " [80, 134, 246, 120],\n",
              " [80, 134, 246, 120, 3],\n",
              " [80, 134, 246, 120, 3, 461],\n",
              " [80, 134, 246, 120, 3, 461, 74],\n",
              " [462, 50],\n",
              " [462, 50, 463],\n",
              " [462, 50, 463, 464],\n",
              " [462, 50, 463, 464, 3],\n",
              " [462, 50, 463, 464, 3, 43],\n",
              " [462, 50, 463, 464, 3, 43, 23],\n",
              " [18, 74],\n",
              " [18, 74, 54],\n",
              " [18, 74, 54, 50],\n",
              " [18, 74, 54, 50, 465],\n",
              " [18, 74, 54, 50, 465, 5],\n",
              " [18, 74, 54, 50, 465, 5, 466],\n",
              " [22, 467],\n",
              " [22, 467, 79],\n",
              " [22, 467, 79, 468],\n",
              " [22, 467, 79, 468, 4],\n",
              " [22, 467, 79, 468, 4, 6],\n",
              " [22, 467, 79, 468, 4, 6, 469],\n",
              " [46, 470],\n",
              " [164, 11],\n",
              " [164, 11, 118],\n",
              " [164, 11, 118, 1],\n",
              " [164, 11, 118, 1, 247],\n",
              " [164, 11, 118, 1, 247, 123],\n",
              " [164, 11, 118, 1, 247, 123, 471],\n",
              " [42, 8],\n",
              " [42, 8, 472],\n",
              " [42, 8, 472, 130],\n",
              " [42, 8, 472, 130, 38],\n",
              " [42, 8, 472, 130, 38, 473],\n",
              " [42, 8, 472, 130, 38, 473, 474],\n",
              " [17, 475],\n",
              " [17, 475, 63],\n",
              " [17, 475, 63, 4],\n",
              " [17, 475, 63, 4, 135],\n",
              " [17, 475, 63, 4, 135, 476],\n",
              " [17, 475, 63, 4, 135, 476, 477],\n",
              " [478, 248],\n",
              " [478, 248, 24],\n",
              " [478, 248, 24, 2],\n",
              " [478, 248, 24, 2, 479],\n",
              " [478, 248, 24, 2, 479, 25],\n",
              " [478, 248, 24, 2, 479, 25, 39],\n",
              " [478, 248, 24, 2, 479, 25, 39, 480],\n",
              " [136, 481],\n",
              " [136, 481, 249],\n",
              " [136, 481, 249, 1],\n",
              " [136, 481, 249, 1, 81],\n",
              " [136, 481, 249, 1, 81, 482],\n",
              " [136, 481, 249, 1, 81, 482, 483],\n",
              " [484, 485],\n",
              " [122, 5],\n",
              " [122, 5, 486],\n",
              " [122, 5, 486, 1],\n",
              " [122, 5, 486, 1, 487],\n",
              " [122, 5, 486, 1, 487, 11],\n",
              " [122, 5, 486, 1, 487, 11, 488],\n",
              " [489, 490],\n",
              " [489, 490, 250],\n",
              " [489, 490, 250, 1],\n",
              " [489, 490, 250, 1, 491],\n",
              " [489, 490, 250, 1, 491, 492],\n",
              " [246, 97],\n",
              " [246, 97, 14],\n",
              " [246, 97, 14, 493],\n",
              " [246, 97, 14, 493, 494],\n",
              " [246, 97, 14, 493, 494, 137],\n",
              " [246, 97, 14, 493, 494, 137, 495],\n",
              " [82, 214],\n",
              " [82, 214, 251],\n",
              " [82, 214, 251, 25],\n",
              " [82, 214, 251, 25, 6],\n",
              " [82, 214, 251, 25, 6, 496],\n",
              " [82, 214, 251, 25, 6, 496, 497],\n",
              " [243, 252],\n",
              " [243, 252, 4],\n",
              " [243, 252, 4, 47],\n",
              " [243, 252, 4, 47, 103],\n",
              " [243, 252, 4, 47, 103, 498],\n",
              " [243, 252, 4, 47, 103, 498, 132],\n",
              " [243, 252, 4, 47, 103, 498, 132, 499],\n",
              " [47, 253],\n",
              " [500, 501],\n",
              " [500, 501, 502],\n",
              " [500, 501, 502, 4],\n",
              " [500, 501, 502, 4, 503],\n",
              " [500, 501, 502, 4, 503, 6],\n",
              " [500, 501, 502, 4, 503, 6, 254],\n",
              " [504, 505],\n",
              " [504, 505, 4],\n",
              " [504, 505, 4, 506],\n",
              " [504, 505, 4, 506, 507],\n",
              " [504, 505, 4, 506, 507, 508],\n",
              " [504, 505, 4, 506, 507, 508, 509],\n",
              " [31, 255],\n",
              " [31, 255, 510],\n",
              " [31, 255, 510, 511],\n",
              " [31, 255, 510, 511, 256],\n",
              " [31, 255, 510, 511, 256, 512],\n",
              " [17, 513],\n",
              " [17, 513, 4],\n",
              " [17, 513, 4, 514],\n",
              " [17, 513, 4, 514, 181],\n",
              " [17, 513, 4, 514, 181, 515],\n",
              " [17, 513, 4, 514, 181, 515, 516],\n",
              " [517, 518],\n",
              " [517, 518, 8],\n",
              " [517, 518, 8, 257],\n",
              " [517, 518, 8, 257, 519],\n",
              " [517, 518, 8, 257, 519, 520],\n",
              " [33, 133],\n",
              " [33, 133, 521],\n",
              " [129, 60],\n",
              " [129, 60, 56],\n",
              " [129, 60, 56, 522],\n",
              " [129, 60, 56, 522, 1],\n",
              " [129, 60, 56, 522, 1, 523],\n",
              " [129, 60, 56, 522, 1, 523, 524],\n",
              " [17, 34],\n",
              " [17, 34, 98],\n",
              " [17, 34, 98, 3],\n",
              " [17, 34, 98, 3, 525],\n",
              " [17, 34, 98, 3, 525, 1],\n",
              " [17, 34, 98, 3, 525, 1, 138],\n",
              " [17, 34, 98, 3, 525, 1, 138, 526],\n",
              " [82, 258],\n",
              " [82, 258, 251],\n",
              " [82, 258, 251, 24],\n",
              " [82, 258, 251, 24, 259],\n",
              " [82, 258, 251, 24, 259, 527],\n",
              " [82, 258, 251, 24, 259, 527, 528],\n",
              " [529, 530],\n",
              " [529, 530, 1],\n",
              " [529, 530, 1, 531],\n",
              " [529, 530, 1, 531, 532],\n",
              " [529, 530, 1, 531, 532, 3],\n",
              " [529, 530, 1, 531, 532, 3, 533],\n",
              " [82, 81],\n",
              " [82, 81, 33],\n",
              " [82, 81, 33, 8],\n",
              " [82, 81, 33, 8, 257],\n",
              " [82, 81, 33, 8, 257, 534],\n",
              " [128, 1],\n",
              " [128, 1, 535],\n",
              " [536, 1],\n",
              " [536, 1, 537],\n",
              " [536, 1, 537, 538],\n",
              " [536, 1, 537, 538, 218],\n",
              " [536, 1, 537, 538, 218, 539],\n",
              " [258, 101],\n",
              " [258, 101, 260],\n",
              " [258, 101, 260, 540],\n",
              " [258, 101, 260, 540, 541],\n",
              " [135, 542],\n",
              " [135, 542, 543],\n",
              " [135, 542, 543, 54],\n",
              " [135, 542, 543, 54, 118],\n",
              " [135, 542, 543, 54, 118, 544],\n",
              " [545, 546],\n",
              " [545, 546, 1],\n",
              " [545, 546, 1, 547],\n",
              " [545, 546, 1, 547, 3],\n",
              " [545, 546, 1, 547, 3, 259],\n",
              " [545, 546, 1, 547, 3, 259, 548],\n",
              " [549, 261],\n",
              " [549, 261, 550],\n",
              " [549, 261, 550, 3],\n",
              " [549, 261, 550, 3, 551],\n",
              " [549, 261, 550, 3, 551, 552],\n",
              " [61, 553],\n",
              " [228, 1],\n",
              " [228, 1, 554],\n",
              " [228, 1, 554, 5],\n",
              " [228, 1, 554, 5, 555],\n",
              " [228, 1, 554, 5, 555, 8],\n",
              " [228, 1, 554, 5, 555, 8, 62],\n",
              " [229, 5],\n",
              " [229, 5, 556],\n",
              " [229, 5, 556, 4],\n",
              " [229, 5, 556, 4, 65],\n",
              " [229, 5, 556, 4, 65, 557],\n",
              " [229, 5, 556, 4, 65, 557, 558],\n",
              " [559, 560],\n",
              " [559, 560, 561],\n",
              " [559, 560, 561, 14],\n",
              " [559, 560, 561, 14, 562],\n",
              " [559, 560, 561, 14, 562, 8],\n",
              " [559, 560, 561, 14, 562, 8, 205],\n",
              " [563, 57],\n",
              " [563, 57, 22],\n",
              " [563, 57, 22, 250],\n",
              " [563, 57, 22, 250, 564],\n",
              " [563, 57, 22, 250, 564, 565],\n",
              " [7, 59],\n",
              " [7, 59, 566],\n",
              " [7, 59, 566, 213],\n",
              " [7, 59, 566, 213, 4],\n",
              " [7, 59, 566, 213, 4, 17],\n",
              " [7, 59, 566, 213, 4, 17, 130],\n",
              " [7, 59, 566, 213, 4, 17, 130, 567],\n",
              " [28, 99],\n",
              " [201, 8],\n",
              " [201, 8, 230],\n",
              " [201, 8, 230, 1],\n",
              " [201, 8, 230, 1, 568],\n",
              " [201, 8, 230, 1, 568, 569],\n",
              " [201, 8, 230, 1, 568, 569, 139],\n",
              " [570, 4],\n",
              " [570, 4, 231],\n",
              " [570, 4, 231, 1],\n",
              " [570, 4, 231, 1, 571],\n",
              " [570, 4, 231, 1, 571, 3],\n",
              " [570, 4, 231, 1, 571, 3, 572],\n",
              " [570, 4, 231, 1, 571, 3, 572, 573],\n",
              " [574, 232],\n",
              " [574, 232, 3],\n",
              " [574, 232, 3, 168],\n",
              " [574, 232, 3, 168, 575],\n",
              " [574, 232, 3, 168, 575, 576],\n",
              " [17, 577],\n",
              " [17, 577, 63],\n",
              " [17, 577, 63, 4],\n",
              " [17, 577, 63, 4, 578],\n",
              " [17, 577, 63, 4, 578, 145],\n",
              " [17, 577, 63, 4, 578, 145, 579],\n",
              " [580, 581],\n",
              " [580, 581, 69],\n",
              " [580, 581, 69, 16],\n",
              " [580, 581, 69, 16, 582],\n",
              " [580, 581, 69, 16, 582, 139],\n",
              " [64, 57],\n",
              " [583, 256],\n",
              " [583, 256, 8],\n",
              " [583, 256, 8, 65],\n",
              " [583, 256, 8, 65, 92],\n",
              " [583, 256, 8, 65, 92, 584],\n",
              " [585, 249],\n",
              " [585, 249, 3],\n",
              " [585, 249, 3, 586],\n",
              " [585, 249, 3, 586, 587],\n",
              " [585, 249, 3, 586, 587, 1],\n",
              " [585, 249, 3, 586, 587, 1, 588],\n",
              " [589, 254],\n",
              " [589, 254, 140],\n",
              " [589, 254, 140, 3],\n",
              " [589, 254, 140, 3, 247],\n",
              " [590, 591],\n",
              " [590, 591, 592],\n",
              " [590, 591, 592, 10],\n",
              " [590, 591, 592, 10, 9],\n",
              " [590, 591, 592, 10, 9, 593],\n",
              " [590, 591, 592, 10, 9, 593, 171],\n",
              " [590, 591, 592, 10, 9, 593, 171, 594],\n",
              " [595, 68],\n",
              " [595, 68, 1],\n",
              " [595, 68, 1, 252],\n",
              " [595, 68, 1, 252, 3],\n",
              " [595, 68, 1, 252, 3, 596],\n",
              " [595, 68, 1, 252, 3, 596, 597],\n",
              " [66, 67],\n",
              " [42, 8],\n",
              " [42, 8, 9],\n",
              " [42, 8, 9, 598],\n",
              " [42, 8, 9, 598, 599],\n",
              " [42, 8, 9, 598, 599, 600],\n",
              " [42, 8, 9, 598, 599, 600, 1],\n",
              " [42, 8, 9, 598, 599, 600, 1, 601],\n",
              " [42, 8, 9, 598, 599, 600, 1, 601, 137],\n",
              " [602, 20],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLatqKUEvBUi",
        "outputId": "024fcf16-38fc-4293-f07c-62295e68b4dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "c296737d-a45b-48ae-c1fd-8e0af68af28e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  83,   2],\n",
              "       [  0,   0,   0, ...,  83,   2,  55],\n",
              "       [  0,   0,   0, ...,   0,  84,  55],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   1,  79,  31],\n",
              "       [  0,   0,   0, ...,  79,  31,  46],\n",
              "       [  0,   0,   0, ...,  31,  46, 754]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "e3cd1629-d0cc-4552-dc62-0b1a5ce1a498"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1406, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "b68d959d-082d-4d5b-ab58-20ffbdb7946d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1406,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OL3vrEXSs_s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=755)"
      ],
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "4ef8fe75-7461-4aba-b165-076e9b230d14"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1406, 755)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(755, 100, input_length=12))\n",
        "model.add(LSTM(150))  # single LSTM is fine\n",
        "model.add(Dense(755, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wo-OYfHpTK2o",
        "outputId": "78a9a302-8101-4c75-83d3-f41c33ed5bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OxxXkrSXfIBv",
        "outputId": "6412b259-0ded-40c6-b76b-31b7fc25b913"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m75,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m755\u001b[0m)            │       \u001b[38;5;34m114,005\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">755</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">114,005</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,020,317\u001b[0m (3.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,020,317</span> (3.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m340,105\u001b[0m (1.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,105</span> (1.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m680,212\u001b[0m (2.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">680,212</span> (2.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "5b804ca5-857b-4337-b01c-5e821bb979df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.0299 - loss: 6.5761\n",
            "Epoch 2/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0515 - loss: 6.0576\n",
            "Epoch 3/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0453 - loss: 5.9737\n",
            "Epoch 4/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0461 - loss: 5.9298\n",
            "Epoch 5/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0514 - loss: 5.8326\n",
            "Epoch 6/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0531 - loss: 5.6547\n",
            "Epoch 7/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0506 - loss: 5.4902\n",
            "Epoch 8/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0624 - loss: 5.3968\n",
            "Epoch 9/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.0680 - loss: 5.1722\n",
            "Epoch 10/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0947 - loss: 4.9043\n",
            "Epoch 11/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1028 - loss: 4.7744\n",
            "Epoch 12/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1260 - loss: 4.6061\n",
            "Epoch 13/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1509 - loss: 4.2964\n",
            "Epoch 14/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1644 - loss: 4.1928\n",
            "Epoch 15/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1922 - loss: 3.9649\n",
            "Epoch 16/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2324 - loss: 3.7627\n",
            "Epoch 17/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2715 - loss: 3.5895\n",
            "Epoch 18/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3268 - loss: 3.3699\n",
            "Epoch 19/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.3862 - loss: 3.1719\n",
            "Epoch 20/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4020 - loss: 3.0204\n",
            "Epoch 21/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4420 - loss: 2.8686\n",
            "Epoch 22/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5049 - loss: 2.7014\n",
            "Epoch 23/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5628 - loss: 2.4962\n",
            "Epoch 24/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5834 - loss: 2.3059\n",
            "Epoch 25/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6430 - loss: 2.1497\n",
            "Epoch 26/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6546 - loss: 2.0495\n",
            "Epoch 27/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7067 - loss: 1.8334\n",
            "Epoch 28/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7247 - loss: 1.7765\n",
            "Epoch 29/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7230 - loss: 1.6182\n",
            "Epoch 30/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7604 - loss: 1.5631\n",
            "Epoch 31/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7704 - loss: 1.4618\n",
            "Epoch 32/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7975 - loss: 1.3545\n",
            "Epoch 33/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8137 - loss: 1.2436\n",
            "Epoch 34/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8500 - loss: 1.1463\n",
            "Epoch 35/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8475 - loss: 1.1111\n",
            "Epoch 36/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8764 - loss: 1.0161\n",
            "Epoch 37/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8937 - loss: 0.9159\n",
            "Epoch 38/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8981 - loss: 0.8599\n",
            "Epoch 39/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8998 - loss: 0.8342\n",
            "Epoch 40/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9039 - loss: 0.7846\n",
            "Epoch 41/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9094 - loss: 0.7033\n",
            "Epoch 42/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9179 - loss: 0.7010\n",
            "Epoch 43/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9242 - loss: 0.6258\n",
            "Epoch 44/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9271 - loss: 0.5885\n",
            "Epoch 45/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9215 - loss: 0.5644\n",
            "Epoch 46/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9237 - loss: 0.5203\n",
            "Epoch 47/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9329 - loss: 0.5009\n",
            "Epoch 48/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9307 - loss: 0.5054\n",
            "Epoch 49/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9197 - loss: 0.4843\n",
            "Epoch 50/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9248 - loss: 0.4459\n",
            "Epoch 51/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9408 - loss: 0.3893\n",
            "Epoch 52/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9284 - loss: 0.4011\n",
            "Epoch 53/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9329 - loss: 0.3957\n",
            "Epoch 54/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9261 - loss: 0.3660\n",
            "Epoch 55/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9282 - loss: 0.3601\n",
            "Epoch 56/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9317 - loss: 0.3221\n",
            "Epoch 57/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9431 - loss: 0.3138\n",
            "Epoch 58/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9290 - loss: 0.3204\n",
            "Epoch 59/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9352 - loss: 0.3021\n",
            "Epoch 60/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9315 - loss: 0.2873\n",
            "Epoch 61/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9270 - loss: 0.2792\n",
            "Epoch 62/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9273 - loss: 0.2723\n",
            "Epoch 63/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9348 - loss: 0.2621\n",
            "Epoch 64/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9350 - loss: 0.2509\n",
            "Epoch 65/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9381 - loss: 0.2339\n",
            "Epoch 66/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9462 - loss: 0.2191\n",
            "Epoch 67/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9297 - loss: 0.2426\n",
            "Epoch 68/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9359 - loss: 0.2159\n",
            "Epoch 69/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9373 - loss: 0.2308\n",
            "Epoch 70/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9310 - loss: 0.2203\n",
            "Epoch 71/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9368 - loss: 0.2204\n",
            "Epoch 72/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9368 - loss: 0.1978\n",
            "Epoch 73/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9332 - loss: 0.1936\n",
            "Epoch 74/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9373 - loss: 0.1898\n",
            "Epoch 75/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9155 - loss: 0.2255\n",
            "Epoch 76/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9373 - loss: 0.1974\n",
            "Epoch 77/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9308 - loss: 0.1902\n",
            "Epoch 78/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9342 - loss: 0.1873\n",
            "Epoch 79/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9376 - loss: 0.1865\n",
            "Epoch 80/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9305 - loss: 0.2012\n",
            "Epoch 81/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9249 - loss: 0.1950\n",
            "Epoch 82/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9351 - loss: 0.1673\n",
            "Epoch 83/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9364 - loss: 0.1646\n",
            "Epoch 84/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9392 - loss: 0.1624\n",
            "Epoch 85/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9385 - loss: 0.1671\n",
            "Epoch 86/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9326 - loss: 0.1683\n",
            "Epoch 87/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9303 - loss: 0.1603\n",
            "Epoch 88/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9415 - loss: 0.1445\n",
            "Epoch 89/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9375 - loss: 0.1377\n",
            "Epoch 90/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9269 - loss: 0.1652\n",
            "Epoch 91/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9266 - loss: 0.1532\n",
            "Epoch 92/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9318 - loss: 0.1583\n",
            "Epoch 93/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9313 - loss: 0.1694\n",
            "Epoch 94/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9240 - loss: 0.1526\n",
            "Epoch 95/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9285 - loss: 0.1517\n",
            "Epoch 96/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9332 - loss: 0.1601\n",
            "Epoch 97/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9230 - loss: 0.1542\n",
            "Epoch 98/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9484 - loss: 0.1330\n",
            "Epoch 99/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9291 - loss: 0.1539\n",
            "Epoch 100/100\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9407 - loss: 0.1353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5494706720>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "_UwjQMQpwGXD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = \"what is\"\n",
        "\n",
        "for i in range(20):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "7331bb74-58da-448d-e16c-8ff0e91066f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "what is align\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "what is align with\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "what is align with the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "what is align with the published\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "what is align with the published dsmp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "what is align with the published dsmp one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "what is align with the published dsmp one on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "what is align with the published dsmp one on one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "what is align with the published dsmp one on one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "what is align with the published dsmp one on one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "what is align with the published dsmp one on one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "what is align with the published dsmp one on one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "what is align with the published dsmp one on one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "what is align with the published dsmp one on one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one one one one one\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "what is align with the published dsmp one on one one one one one one one one one one one one one\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92y7gE6pj9EZ"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}